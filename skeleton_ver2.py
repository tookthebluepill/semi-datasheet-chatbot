import streamlit as st
import os
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
try:
    from langchain_classic.chains import RetrievalQA
except ImportError:
    from langchain_community.chains import RetrievalQA

# API í‚¤ ì„¤ì •
os.environ["GOOGLE_API_KEY"] = ""

st.title("ë°˜ë„ì²´ ë°ì´í„°ì‹œíŠ¸ ì±—ë´‡")

# ìºì‹± í•¨ìˆ˜: PDF ë¶„ì„ì€ 'íŒŒì¼ì´ ë°”ë€” ë•Œë§Œ' í•œ ë²ˆ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ì €ì¥í•´ë‘¡ë‹ˆë‹¤.
@st.cache_resource
def get_vectorstore(file_path):
    # 1. ë¬¸ì„œ ë¡œë“œ
    loader = PyPDFLoader(file_path)
    pages = loader.load_and_split()
    
    # 2. ì²­í‚¹ (Chunking)
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    texts = text_splitter.split_documents(pages)
    
    # 3. ì„ë² ë”© (ë¡œì»¬ CPU ì‚¬ìš©)
    embeddings = HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-MiniLM-L6-v2"
    )
    
    # 4. ë²¡í„° DB ìƒì„±
    vectorstore = FAISS.from_documents(texts, embeddings)
    return vectorstore

# íŒŒì¼ ì—…ë¡œë“œ UI
uploaded_file = st.file_uploader("ë°ì´í„°ì‹œíŠ¸ PDFë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type="pdf")

if uploaded_file is not None:
    # íŒŒì¼ì„ ì„ì‹œ ì €ì¥
    file_path = "temp.pdf"
    with open(file_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    
    # [í•µì‹¬] ìŠ¤í”¼ë„ˆê°€ ì²« ì‹¤í–‰ ë•Œë§Œ ëŒê³ , ë‘ ë²ˆì§¸ë¶€í„°ëŠ” ì¦‰ì‹œ í†µê³¼í•©ë‹ˆë‹¤.
    with st.spinner("ë¬¸ì„œ ë¶„ì„ ì¤‘... (ì²˜ìŒì—ë§Œ ì˜¤ë˜ ê±¸ë¦½ë‹ˆë‹¤)"):
        vectorstore = get_vectorstore(file_path)
        st.success("ë¶„ì„ ì™„ë£Œ! ë°ì´í„°ì‹œíŠ¸ì— ê´€ë ¨ ì§ˆë¬¸ì„ í•˜ì‹œì˜¤.")

    # ì§ˆë¬¸ ì…ë ¥
    query = st.text_input("ì§ˆë¬¸:")
    
    if query:
        # ëª¨ë¸: Gemini Flash Latest (ë¹ ë¥´ê³  ë¬´ë£Œ)
        llm = ChatGoogleGenerativeAI(model="gemini-flash-latest", temperature=0)
        
        qa_chain = RetrievalQA.from_chain_type(
            llm=llm,
            chain_type="stuff",
            retriever=vectorstore.as_retriever(),
            return_source_documents=True
        )
        
        result = qa_chain.invoke({"query": query})
        
        st.write("### ğŸ¤– ë‹µë³€:")
        st.write(result['result'])
        
        st.write("---")
        st.write("### ğŸ“„ ì°¸ê³ í•œ í˜ì´ì§€:")
        for doc in result['source_documents']:
            st.caption(f"Page {doc.metadata.get('page', '?')}: {doc.page_content[:150]}...")