import streamlit as st
import os
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
try:
    from langchain_classic.chains import RetrievalQA
except ImportError:
    from langchain_community.chains import RetrievalQA

# API í‚¤ ì„¤ì •
os.environ["GOOGLE_API_KEY"] = ""

st.title("ë°˜ë„ì²´ ë°ì´í„°ì‹œíŠ¸ AI ì±—ë´‡")

uploaded_file = st.file_uploader("ë°ì´í„°ì‹œíŠ¸ PDFë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type="pdf")

if uploaded_file is not None:
    with open("temp.pdf", "wb") as f:
        f.write(uploaded_file.getbuffer())
    
    with st.spinner("ë¬¸ì„œ ë¶„ì„ ì¤‘... (ë¡œì»¬ ì„ë² ë”© ì‚¬ìš©)"):
        # ë¬¸ì„œ ë¡œë“œ
        loader = PyPDFLoader("temp.pdf")
        pages = loader.load_and_split()
        
        # ì²­í‚¹ (Chunking)
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        texts = text_splitter.split_documents(pages)
        
        # [í•µì‹¬ ìˆ˜ì •] GoogleEmbeddings -> HuggingFaceEmbeddings
        # ì´ ëª¨ë¸(all-MiniLM-L6-v2)ì€ ì‘ê³  ë¹¨ë¼ì„œ ë…¸íŠ¸ë¶ CPUë¡œë„ ì¶©ë¶„í•©ë‹ˆë‹¤.
        embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/all-MiniLM-L6-v2"
        )
        
        # ë²¡í„° DB ìƒì„±
        vectorstore = FAISS.from_documents(texts, embeddings)
        
        st.success("ë¶„ì„ ì™„ë£Œ! ì§ˆë¬¸í•´ì£¼ì„¸ìš”.")

    query = st.text_input("ì§ˆë¬¸:")
    
    if query:
        # ë‹µë³€ ìƒì„±ì€ ì—¬ì „íˆ ë˜‘ë˜‘í•œ Geminiê°€ ë‹´ë‹¹í•©ë‹ˆë‹¤
        llm = ChatGoogleGenerativeAI(model="gemini-flash-latest", temperature=0)
        
        qa_chain = RetrievalQA.from_chain_type(
            llm=llm,
            chain_type="stuff",
            retriever=vectorstore.as_retriever(),
            return_source_documents=True
        )
        
        result = qa_chain.invoke({"query": query})
        
        st.write("### ğŸ¤– ë‹µë³€:")
        st.write(result['result'])
        
        st.write("---")
        st.write("### ğŸ“„ ì°¸ê³ í•œ í˜ì´ì§€:")
        for doc in result['source_documents']:
            st.caption(f"Page {doc.metadata.get('page', '?')}: {doc.page_content[:150]}...")